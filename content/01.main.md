

## Abstract
As sequencing costs have steadily decreased in recent years, having computationally efficient methods for variant discovery and genotyping has become increasingly important. Recent work have shown that genotyping can be done efficiently and accurately using *alignment-free* methods that are based on analysing kmers from sequenced reads. In particular, we have recently presented the KAGE genotyper, which uses an efficient pangenome representation of known individuals in a population to further increase accuracy and efficiency. While existing genotypers like KAGE use the *Central Processing Unit* (CPU) to count and analyse kmers, the *Graphical Processing Unit* (GPU)  has shown to be promising for reducing runtime for similar problems.

We here present *GKAGE*, a new and improved version of KAGE that utilises the GPU to further increase the computational efficiency. This is done by counting and analysing large amounts of kmers in the many parallel cores of a GPU. We show that GKAGE is, on comparable cost hardware, able to genotype an individual up to a magnitude faster than KAGE while producing the same output, which makes it by far the fastest genotyper available today. GKAGE can run on consumer-grade GPUs, and enables genotyping of a human sample in only a matter of minutes without the need for expensive high-performance computers. GKAGE is open source and available at <https://github.com/kage-genotyper/kage>.

## Introduction
The cost of sequencing a full human genome has fallen drastically in recent years, and consumers can now get their whole genome sequenced for a few hundred dollars [@crow], a fraction of what was the price only a few years ago. As millions of genomes are likely to be sequenced in the coming years, there is an ever-increasing need for efficient methods for analysing this genomic data. At the core of such analysis is *variant detection*, determining which genetic variants are present in a sample based on the sequenced reads.

Recent methods [@kage; @malva; @pangenie; @graphtyper] have shown that detecting variants in a human sample can be performed efficiently and with high accuracy by *genotyping* the sample against an existing database of known human variation. Such methods use prior knowledge from e.g. the 1000 Genomes Project [@thousand_genomes] about where in the genome individuals frequently have variation, and for each such genetic variant uses the genomic reads from the sample to infer the most likely genotype. While such methods traditionally have been based on aligning reads to a reference genome, which is slow, recent *alignment-free methods* have shown that drastic speedup can be achieved by instead analysing kmers from the sequenced reads. In a recent publication [@kage], we proposed a highly efficient alignment-free method, KAGE, that uses prior knowledge from a population to achieve high genotyping accuracy while being more efficient than other alignment-free genotypers. Alignment-free genotypers, like KAGE, generally work by using an index (e.g. a hashmap) that enables “mapping” of kmers from input reads to alleles of known genetic variants. The genotyping is then performed by counting how many reads support the various alleles of the variants of interest. 

In contrast to other genotypers, especially alignment-based genotypers like GATK [@gatk], the time-consuming steps of KAGE (like processing and counting kmers) can benefit from the massive parallelization that the Graphical Processing Unit (GPU) offers [@gerbil, @kmc2]. Here, we show that by applying GPU acceleration to the compute-heavy parts of KAGE, we end up with a very efficient genotyper, GKAGE. GKAGE uses the GPU to process genomic reads, extract kmers and count how many kmers support alleles of genetic variants. We show that GKAGE gives significant speedup (up to 10X) over the original KAGE genotyper (which was already faster than any other genotyper), while producing the exact same output. GKAGE has been implemented so that it is able to run even on standard consumer GPUs, and is able to genotype a whole human sample in a matter of minutes.

## Results
GKAGE is a GPU accelerated version of the recently published KAGE genotyper. GKAGE uses CUDA-powered GPUs to efficiently parse and encode kmers from reads, and genotype a set of known SNPs and indels based on the kmer counts. GKAGE produces output that is identical to that of KAGE, with reduced runtime on systems that support the CUDA-interface for GPU acceleration. The software is open source and available at <https://github.com/kage-genotyper/kage>. As part of GKAGE, we have also implemented a static GPU hashmap for counting kmers through a Python interface, available at <https://github.com/kage-genotyper/cucounter>.

We have recently shown that KAGE is an order of magnitude faster than existing genotypers while giving better or comparable accuracy [@kage]. We thus only benchmark GKAGE against KAGE to show the effect of GPU acceleration. We do this by running GKAGE and KAGE on a human whole genome sample (15x coverage) on two different systems:

1. A high-performance server with an AMD EPYC 7742 64-Core CPU and two NVIDIA Tesla V100 GPUs. KAGE was run using 16 threads and GKAGE was run using one GPU.

2. A regular desktop computer with an 11th Gen Intel(R) Core(TM) i5-11400F @ 2.60GHz CPU with 6 cores and a NVIDIA GTX 1660 super GPU. KAGE was run using 6 threads.

Table 1 shows the runtimes on these two systems. GKAGE is approximately 5x faster on the high-end system and more 10x faster on the desktop computer.


|                           | KAGE     | GKAGE   |
|---------------------------|----------|---------|
| Desktop computer          | 1993 sec | 178 sec |
| High-performance computer | 510 sec  | 94 sec |
Table: Running times of KAGE and GKAGE
{#tbl:table1}




## Methods

### Implementation
Here we describe more in detail how GKAGE has been implemented. While GKAGE is implemented as part of KAGE, and in large parts uses the same code, compute-heavy parts have been reimplemented so that the GPU is utilised. GKAGE implements GPU support for two bottleneck components of KAGE that were suitable for GPU acceleration:

**Reading and encoding kmers** from a FASTA/FASTQ file is achieved in KAGE by using BioNumPy [@bionumpy], a Python library built on top of NumPy [@numpy]. BioNumPy uses NumPy to efficiently read chunks of DNA reads from fasta files, encode the bases to a 2-bit representation, and then encode the valid kmers as 64-bit integer representations in an array. GPU support for this step was achieved by utilizing CuPy [@cupy], a GPU accelerated computing library with an interface that closely follows that of NumPy. This was implemented by replacing the NumPy module in BioNumPy's modules with CuPy, effectively replacing all NumPy function calls with calls to CuPy's functions providing the same functionality, although GPU accelerated. This strategy worked out of the box for most parts of the BioNumPy solution, with only a few modifications having to be made due to certain functions in NumPy's interface not being supported by CuPy. 


**Counting kmers** As part of GKAGE, we have implemented a static hashtable for counting a predefined set of kmers on the GPU. The implementation supports parallel and high-throughput hashing and counting of large chunks of kmers simultaneously on the GPU.
This static hashtable is implemented as a C++ class in CUDA [@cuda], with two arrays of 64-bit and 32-bit unsigned integers to represent kmers (keys) and counts (values) respectively. CUDA kernels are implemented that handle insertion (only once during initialization of the hashtable), counting and querying of kmers. The hashtable uses open addressing and a simple linear probing scheme with a murmur hash [@murmur] for the keys.


To find a kmer *k*'s position in the hashtable, the initial probe position *$p_0$* is found by computing

$$
  p_0=hash(k) \bmod c
$$


where *hash* is a murmur hash function and *c* is the capacity of the hashtable.
If \textit{$p_0$} is occupied by a different kmer than \textit{k}, the next probing position \textit{$p_i$} can be computed given the previous probing position \textit{$p_{i-1}$} with

$$
  p_i=(p_{i-1} + 1) \bmod c
$$

The probing will continue until either *k* or an empty slot in the hashtable is observed.

The hashtable supports three main operations: insertion, counting and querying.
In each of the cases, the input is an array of 2-bit encoded kmers, and for querying the return value is an array of counts associated with the input kmers. For insertion, counting or querying of *n* kmers, *n* CUDA threads are launched. Each thread is then responsible for fulfilling the relevant operation associated with the kmer, i.e. incrementing or fetching the count associated with the kmer in the hashtable, all achieved using the probing scheme previously described. Furthermore, for insertions and count updates, CUDA atomic operations are used to avoid race conditions. To use the hashtable class in Python, C++ bindings are implemented using pybind11 [@pybind11]. 

Since KAGE only needs to count kmers that are preselected to represent alleles of known variants, which typically is only a small subset of the kmers present in genomic reads, the hashmap needed for this requires only a few gigabytes of memory.
Thus, when genotyping a human sample, a GPU with 4GB of memory is sufficient (see details below).


### Benchmarks
Benchmarking was performed on two different computer systems, as described in the Results section, using simulated reads for a whole genome sample with 15x coverage. A Snakemake pipeline for reproducing the benchmarking results can be found at <https://github.com/kage-genotyper/GKAGE-benchmarking>.

## Discussion
We have presented GKAGE, a GPU accelerated genotyper. Our results show that alignment-free genotyping is an ideal problem for GPU acceleration. While the existing KAGE genotyper is already fast by today’s standards, GKAGE is considerably faster, and enables rapid genotyping on even consumer computers. We believe these results are relevant as the experimental side of whole-genome sequencing is continuously becoming cheaper and more common.

Since the original KAGE genotyper was implemented mainly using the array programming libraries NumPy and BioNumPy in Python, adding GPU-support to the existing code base was possible to do in a clean way by using the CuPy library as well as implementing some custom CUDA kernels with Python wrappers. We thus believe that this work shows that adding GPU-support to existing tools is feasible and can be beneficial in cases where many independent operations are performed on an array of data, which is common for computational biology problems. As GPUs are steadily becoming cheaper and more available, we thus believe there might be a huge potential in improving the performance of existing tools and methods, which in many cases can be done quite easily through the Python ecosystem with packages such as CuPy [@cupy], Numba [@numba] and BioNumPy [@bionumpy].



[@malva]: doi:10.1016/j.isci.2019.07.011
[@kage]: doi:10.1186/s13059-022-02771-2
[@jellyfish]: doi:10.1093/bioinformatics/btr011 
[@numpy]: doi:10.1038/s41586-020-2649-2
[@thousand_genomes]: doi:10.1038/nature15393
[@graphtyper]: doi:10.1038/ng.3964
[@gerbil]: doi:10.1186/s13015-017-0097-9
[@kmc2]: doi:10.1109/ASAP.2018.8445084
[@bionumpy]: doi:10.1101/2022.12.21.521373
[@numba]: doi:10.1145/2833157.2833162
[@pangenie]: doi:10.1038/s41588-022-01043-w
[@crow]: doi:10.1016/j.cell.2019.02.041
[@gatk]: doi:10.1101/201178
